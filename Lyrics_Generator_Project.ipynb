{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lyrics_Generator_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyasingh30/LyricsGeneration/blob/master/Lyrics_Generator_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMKOxHr48K5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n",
        " \n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Activation,LSTM,Dense,CuDNNLSTM, Flatten, Bidirectional, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "np.random.seed(10)\n",
        " \n",
        "BATCH_SIZE = 32\n",
        "maxlen = 50 ##timesteps\n",
        "epochs = 10\n",
        "MIN_WORD_FREQUENCY = 10\n",
        "song_count = 1000\n",
        "## Reading the kaggle input ~55k songs\n",
        "df=pd.read_csv('/content/drive/My Drive/Lyrics_Gen/song6000.csv',engine=\"python\")[:song_count]\n",
        "data=np.array(df)\n",
        " \n",
        "text=\" \"\n",
        "for ix in range(len(data)):\n",
        "    text+=str(data[ix])\n",
        "# text = text.lower()\n",
        "text = text.lower().replace('\\n', ' \\n ')\n",
        "text = re.sub(\" +\" , \" \", text)\n",
        "print('Corpus length in characters:', len(text))\n",
        "corpus = [w for w in text.split(' ') if w.strip() != '' or w == '\\n'\n",
        "          and (w[0] not in [\"(\",\"[\" ] and w[-1] not in [\")\",\"]\" ])]\n",
        "while \"\" in corpus:\n",
        "    corpus.remove(\"\")\n",
        "print('Corpus length in words:', len(corpus))\n",
        " \n",
        "text[:1000]\n",
        " \n",
        "\"\"\"### Filtering vocabulary based on word frequency\"\"\"\n",
        " \n",
        "word_freq = {}\n",
        "for word in corpus:\n",
        "    word_freq[word] = word_freq.get(word, 0) + 1\n",
        " \n",
        "ignored_words = set()\n",
        "for k, v in word_freq.items():\n",
        "    if word_freq[k] < MIN_WORD_FREQUENCY:\n",
        "        ignored_words.add(k)\n",
        " \n",
        "vocab = set(corpus)\n",
        "print('Unique words before ignoring:', len(vocab))\n",
        "print('Ignoring words with frequency <', MIN_WORD_FREQUENCY)\n",
        "#vocab = sorted(set(vocab) - ignored_words)\n",
        "print('Unique words after ignoring:', len(vocab))\n",
        "# print_vocabulary(vocabulary, words)\n",
        " \n",
        "\"\"\"### Creating Vocabulary and char, index mappings\"\"\"\n",
        " \n",
        "word_ix={c:i for i,c in enumerate(vocab)}\n",
        "ix_word={i:c for i,c in enumerate(vocab)}\n",
        " \n",
        "\"\"\"### Filtering corpus based on new vocabulary\"\"\"\n",
        " \n",
        "sentences = []\n",
        "next_words = []\n",
        "ignored = 0\n",
        "for i in range(0, len(corpus) - maxlen):\n",
        "    # Only add the sequences where no word is in ignored_words\n",
        "    if len(set(corpus[i: i+maxlen+1]).intersection(ignored_words)) == 0:\n",
        "        sentences.append(corpus[i: i + maxlen])\n",
        "        next_words.append(corpus[i + maxlen])\n",
        "    else:\n",
        "        ignored = ignored + 1\n",
        "print('Ignored sequences:', ignored)\n",
        "print('Remaining sequences:', len(sentences))\n",
        " \n",
        "\"\"\"### Creating the train and test datasets\"\"\"\n",
        " \n",
        "split_count = int(0.8 * len(sentences))\n",
        "sentences_test = sentences[split_count:]\n",
        "next_words_test = next_words[split_count:]\n",
        "sentences = sentences[:split_count]\n",
        "next_words = next_words[:split_count]\n",
        " \n",
        "\"\"\"### Check vocab size and corpus size\"\"\"\n",
        " \n",
        "vocab_size=len(vocab) ##Dimentions of each char\n",
        "print(vocab_size)\n",
        " \n",
        "len(corpus)\n",
        " \n",
        "def generator(sentence_list, next_word_list, batch_size):\n",
        "    \n",
        "    index = 0\n",
        "    while True:\n",
        "        x = np.zeros((batch_size, maxlen, vocab_size), dtype=np.bool)\n",
        "        y = np.zeros((batch_size, vocab_size), dtype=np.bool)\n",
        "        for i in range(batch_size):\n",
        "            for t, w in enumerate(sentence_list[index]):\n",
        "                x[i, t, word_ix[w]] = 1\n",
        "            y[i, word_ix[next_word_list[index]]] = 1\n",
        " \n",
        "            index = index + 1\n",
        "            if index == maxlen:\n",
        "                index = 0\n",
        "        yield x, y\n",
        " \n",
        "def create_model(timesteps, vocab_size, no_layers=3,dropout=0.2):\n",
        "    '''\n",
        "    Creating the model\n",
        "    '''\n",
        "    model=tf.keras.Sequential()\n",
        "    for i in range(no_layers):\n",
        "        model.add(Bidirectional(CuDNNLSTM(128, return_sequences=True),input_shape=(timesteps,vocab_size)))\n",
        "    model.add(Flatten())\n",
        "    #model.add(Bidirectional(CuDNNLSTM(128), input_shape=(timesteps,vocab_size)))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(vocab_size))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.summary()\n",
        "    model.compile(optimizer=Adam(lr=0.01),loss='categorical_crossentropy')\n",
        "    return model\n",
        " \n",
        "model = create_model(maxlen, vocab_size)\n",
        " \n",
        "keras.__version__\n",
        " \n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    '''\n",
        "    helper function to sample an index from a probability array\n",
        "    '''\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        " \n",
        "def on_epoch_end(epoch, logs):\n",
        "    '''\n",
        "    Callback function to write output to file after each epoch\n",
        "    '''\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    examples_file.write('\\n----- Generating text after Epoch: %d\\n' % epoch)\n",
        " \n",
        "    # Randomly pick a seed sequence\n",
        "    seed_index = np.random.randint(len(sentences+sentences_test))\n",
        "    seed = (sentences+sentences_test)[seed_index]\n",
        "#     print(seed)\n",
        " \n",
        "    for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
        "        sentence = seed\n",
        "        examples_file.write('----- Diversity:' + str(diversity) + '\\n')\n",
        "        examples_file.write('----- Generating with seed:\\n\"' + ' '.join(sentence) + '\"\\n')\n",
        "        examples_file.write(\"----- Generated lyrics:\\n\")\n",
        "        examples_file.write(' '.join(sentence))\n",
        " \n",
        "        for i in range(50):\n",
        "            x_pred = np.zeros((1, maxlen, vocab_size))\n",
        "#             print(\"sentence len: {0}\".format(len(sentence)))\n",
        "            for t, word in enumerate(sentence):\n",
        "#                 print(word)\n",
        "                x_pred[0, t,word_ix[word]] = 1\n",
        " \n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_word_pred = ix_word[next_index]\n",
        " \n",
        "            sentence = sentence[1:]\n",
        "#             print(sentence)\n",
        "            sentence.append(next_word_pred)\n",
        " \n",
        "            examples_file.write(\" \"+next_word_pred)\n",
        "        examples_file.write('\\n\\n')\n",
        "    examples_file.write('='*80 + '\\n')\n",
        "#     examples_file.flush()\n",
        " \n",
        "\"\"\"### Opening the output file\"\"\"\n",
        " \n",
        "examples_file = open(\"output_data_word.txt\", \"w\")\n",
        " \n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n",
        " \n",
        "\"\"\"### Training the model\"\"\"\n",
        " \n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "import datetime\n",
        "# %load_ext tensorboard\n",
        " \n",
        "file_path = \"./checkpoints/LSTM_LYRICS-epoch{epoch:03d}-words%d-sequence%d-minfreq%d-loss{loss:.4f}-acc{acc:.4f}-val_loss{val_loss:.4f}-val_acc{val_acc:.4f}\" % (\n",
        "    len(vocab),\n",
        "    maxlen,\n",
        "    10\n",
        ")\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', save_best_only=True)\n",
        " \n",
        "checkpoint_path = \"cp.ckpt\"\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        " \n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "callbacks_list = [print_callback, cp_callback]\n",
        "history = model.fit_generator(generator(sentences, next_words, BATCH_SIZE),\n",
        "    steps_per_epoch=int(len(sentences)/BATCH_SIZE) + 1,\n",
        "    epochs=epochs,\n",
        "    validation_data=generator(sentences_test, next_words_test, BATCH_SIZE)\n",
        "                    ,validation_steps=int(len(sentences_test)/BATCH_SIZE) + 1,\n",
        "                   callbacks = callbacks_list)\n",
        " \n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# %tensorboard --logdir logs\n",
        " \n",
        "\"\"\"### Closing the output file\"\"\"\n",
        " \n",
        "examples_file.close()\n",
        " \n",
        "\"\"\"### Plotting Train Loss curve\"\"\"\n",
        " \n",
        "plt.plot(history.history['loss'])\n",
        " \n",
        "\"\"\"### Plotting Validation Loss curve\"\"\"\n",
        " \n",
        "plt.plot(history.history['val_loss'])\n",
        " \n",
        "\"\"\"### Saving the model to disk\"\"\"\n",
        " \n",
        "model.save('keras_model_word.hdf5')\n",
        "# loaded_model = keras.models.load_model('keras_model_word.hdf5')\n",
        " \n",
        "\"\"\"### Loading the model\"\"\"\n",
        " \n",
        "loaded_model = tf.keras.models.load_model('keras_model_word.hdf5')\n",
        " \n",
        "\"\"\"### Testing the model\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PD47enPHMD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_n(model, input_seq, len_out=5):\n",
        "    generated = []\n",
        "    actual = []\n",
        "    # sent=txt[start_index:start_index+maxlen]\n",
        "    sent = input_seq\n",
        "    generated += sent\n",
        "    gen = generated\n",
        "    for i in range(len_out):\n",
        "        x_sample=generated[i:i+maxlen+2]\n",
        "        print(i,i+maxlen+1)\n",
        "        print(x_sample)\n",
        "        x = np.zeros((1,maxlen,vocab_size))\n",
        "        for j in range(maxlen):\n",
        "            print(x_sample[j])\n",
        "            x[0,j,word_ix[x_sample[j]]] = 1\n",
        "        probs = model.predict(x)\n",
        "        probs = np.reshape(probs,probs.shape[1])\n",
        "        ix = np.argmax(probs)\n",
        "        ix=np.random.choice(range(vocab_size),p=probs.ravel())\n",
        "        generated.append(ix_word[ix])\n",
        "    return \" \".join(generated)\n",
        " \n",
        "inp = 'lime and limpid green, a second scene \\n a fight between the blue you once knew \\n floating down, the sound resounds \\n around the icy waters underground \\n jupiter and saturn, oberon, miranda and titania \\n neptune, titan, stars can frighten \\n \\n blinding signs flap \\n flicker, flicker, flicker, blam \\n pow, pow'\n",
        "inp_seq = inp.lower().split(\" \")[:55]\n",
        " \n",
        "predict_n(model, inp_seq, 12)\n",
        " \n",
        "sentences_test[1]\n",
        " \n",
        "maxlen\n",
        " \n",
        "sentences_test[0]\n",
        " \n",
        "sentences_test[3]\n",
        " \n",
        "next_words_test[0]\n",
        " \n",
        "# txt = corpus\n",
        "# start_index = 230\n",
        "for j in range(0, 100, maxlen):\n",
        "    generated = []\n",
        "    actual = []\n",
        "    # sent=txt[start_index:start_index+maxlen]\n",
        "    sent = sentences_test[j]\n",
        "    generated += sent\n",
        "    actual += sent\n",
        "    print(\"#######################\")\n",
        "    print(\"Input - \",\" \".join(generated))\n",
        "    gen = generated\n",
        "    for i in range(min(100,len(generated))):\n",
        "        x_sample=generated[i:i+maxlen]\n",
        "        x = np.zeros((1,maxlen,vocab_size))\n",
        "        for k in range(maxlen):\n",
        "            x[0,k,word_ix[x_sample[k]]] = 1\n",
        "        probs = model.predict(x)\n",
        "        probs = np.reshape(probs,probs.shape[1])\n",
        "#         ix = np.argmax(probs)\n",
        "        ix=np.random.choice(range(vocab_size),p=probs.ravel())\n",
        "        generated.append(ix_word[ix])\n",
        "        print(j)\n",
        "        print(i)\n",
        "        print(next_words_test[j+i])\n",
        "        actual.append(next_words_test[j+i])\n",
        "#         print(i)\n",
        "#         print(next_words_test[j+i])\n",
        "#         if(i==1):\n",
        "#             break\n",
        "    # for i in range(100):\n",
        "    #     x_sample=gen[i:i+maxlen]\n",
        "    #     x=np.zeros((1,maxlen,vocab_size))\n",
        "    #     for j in range(maxlen):\n",
        "    #         x[0,j,char_ix[x_sample[j]]]=1\n",
        "    #     probs=loaded_model.predict(x)[0]\n",
        "    #     ix = np.argmax(probs)\n",
        "    # #     ix=np.random.choice(range(vocab_size),p=probs.ravel())\n",
        "    #     gen+=ix_char[ix]\n",
        "    # # print(\"--------------\")\n",
        "    print(\"Actual ###############\")\n",
        "    print(\" \".join(actual))\n",
        "    print()\n",
        "    print(\"Generated ############### \")\n",
        "    print(\" \".join(generated))\n",
        " \n",
        "print(\"Generated ############### \")\n",
        "print(\" \".join(generated))\n",
        "print()\n",
        "print(\"Actual ###############\")\n",
        "print(\" \".join(actual))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STvlv3oi-UWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl ipecho.net/plain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MozFJ5mw-9sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmLAhtrEcWZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip show flask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivrZPOiHhkq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/drive/My Drive/lyrics_test_taylor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjJrAz7X8i7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir templates -p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KU4Pk5s8mQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0ea942e-a76d-44f4-f713-964b910f43af"
      },
      "source": [
        "%%writefile templates/index.html\n",
        "<!DOCTYPE html>\n",
        "<head>\n",
        "    <title> LYRICS GENERATOR</title>\n",
        "    <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css\">\n",
        "    <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\n",
        "    <script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js\"></script>\n",
        "    <style>\n",
        "         body {\n",
        "  background-image: url('music.jpg');\n",
        "  background-repeat: no-repeat;\n",
        "  background-attachment: fixed;\n",
        "  background-size: 100% 100%;\n",
        " \n",
        "}\n",
        ".design {\n",
        "border-radius: 25px;\n",
        "border: 10px solid  #32a889 ;\n",
        "padding: 100px;\n",
        "width: 60%;\n",
        "height: 1000px;\n",
        "align-items: : center;\n",
        "}\n",
        ".design2 {\n",
        "border : 10px solid  #32a889 ;\n",
        "\n",
        "}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <h1 style=\"color:rgb(8, 15, 10);\" align = \"center\"> LYRICS GENERATOR </h1>\n",
        "    <br>\n",
        "    <br>\n",
        "        <h2 align=\"center\"  style=\"width:1000px; margin:0 auto;\">\n",
        "            <p style=\"font-family:courier;\" align=\"left\" >\n",
        "              Demo for lyrics generation. Write down what you have written till now and we will let\n",
        "              AI complete the piece.\n",
        "            </p>\n",
        "        </h2>\n",
        "        <br/>\n",
        "        <br/>\n",
        "\n",
        "        <div class = \"design2\" align=\"center\" style=\"width:800px; margin:0 auto;\">\n",
        "            <form id=\"optionForm\">\n",
        "              <textarea rows=\"4\" cols=\"100\" placeholder=\"Give us what you got till now..\" id=\"search_text\"></textarea>\n",
        "              <button type=\"button\" id=\"submit_text\">Submit</button>\n",
        "            </form>\n",
        "        </div>\n",
        "        <br/>\n",
        "        <br/>\n",
        "\n",
        "        <div class=\"design\" id=\"results\" align=\"left\" style=\"width:800px; margin:0 auto;font-family:courier;\">\n",
        "\n",
        "        </div>\n",
        "    </body>\n",
        "    <script type=\"text/javascript\">\n",
        "    $(document).ready(function () {\n",
        "  $(\"#submit_text\").click(function () {\n",
        "    var search_text = $(\"#search_text\").val();\n",
        "    console.log(search_text);\n",
        "    $(\"#results\").html('');\n",
        "    $(\"#optiondiv\").html('');\n",
        "    $.ajax({\n",
        "        url: `/lyrics`,\n",
        "        contentType: \"application/json\",\n",
        "        type: 'POST',\n",
        "        dataType: 'json',\n",
        "        data: JSON.stringify({\n",
        "          search_text: search_text\n",
        "        }),\n",
        "        success: function (data) {\n",
        "          $(\"#results\").html('');\n",
        "          console.log(data);\n",
        "          $(\"#results\").append(data.generated);\n",
        "          }\n",
        "          })\n",
        "  })\n",
        "})\n",
        "    </script>\n",
        "\n",
        "</html>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing templates/index.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzhki0IF-r3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%writefile app.py\n",
        "\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask\n",
        "import flask\n",
        "import tensorflow as tf\n",
        "# import five_words as five\n",
        "\n",
       
        "\n",
        "\n",
        "model=tf.keras.models.load_model('/content/drive/My Drive/lyrics_test/keras_model_word.hdf5')\n",
        "app = Flask(__name__, template_folder=\"templates\")\n",
        "run_with_ngrok(app) \n",
        "\n",
        "\n",
        "def infer(prime_text):\n",
        "    prime_text = prime_text.lower().split(\" \")[:55]\n",
        "    lyricmodel = predict_n(model,prime_text,50)\n",
        "    #result = lyricmodel.test(prime_text)\n",
        "    return lyricmodel\n",
        "\n",
        "@app.route('/', methods=['GET'])\n",
        "def webpage():\n",
        "    return flask.render_template('index.html')\n",
        "\n",
        "@app.route('/lyrics', methods = ['POST'])\n",
        "def search(): \n",
        "    content = flask.request.get_json(silent = True)\n",
        "    input_text = content['search_text']\n",
        "    print(input_text)\n",
        "    generated = infer(input_text)\n",
        "    return flask.jsonify({'generated': generated})\n",
        "\n",
        "@app.route('/test', methods=['GET'])\n",
        "def test():\n",
        "    return flask.jsonify({'ping': 'ping_data'})\n",
        "app.run()\n",
        "#app.config['TEMPLATES_AUTO_RELOAD'] = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDn-u4rSUpJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lime and limpid green, a second scene a fight between the blue you once knew floating down, the sound resounds around the icy waters underground jupiter and saturn, oberon, miranda and titania neptune, titan, stars can frighten blinding signs flap flicker, flicker, flicker, blam pow, pow Stairway scare Dan Dare who’s there? Lime and limpid green, the sound surrounds The icy waters under Lime and limpid green, the sound surrounds The icy waters underground"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSui_svM-NG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Give this input in user-interface----> look at her face, it's a wonderful face and it means something special to me look at the way that she when she sees me how lucky can one be? she\\'s just my kind of girl, she makes me feel fine who could ever believe that she could be mine she's just my kind of girl, without her "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
